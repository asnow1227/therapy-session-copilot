# Data capturing
This section is part of the repository Therapy Session Copilot (https://github.com/fsi-hack4autism/therapy-session-copilot), hosted as a part of FSI Hackathon for Autism (https://github.com/fsi-hack4autism).

* Focus is on capturing and normalizing the data for further use
* Data can be captured in a multimodal format - audio, video, and other IoTs. 
* Audio can be input in various languages. 
* Allow BCBA and RBT to input markers, triggers, and progress indicators for the copilot to pay attention to

### Sample Scenarios
* Multi-modal data capture
  * A smartphone app used by RBT - similar to what some RBTs have today
  * Video camera to record the session - this will focus on capturing facial expressions, body language, fluency of tasks, etc.
  * Microphone - this will focus on capturing voice, tone, etc. to determine emotions

### Sample Ideas
[Project Florence -Vision Studio for Video/Image Analysis](https://portal.vision.cognitive.azure.com/gallery/featured)