{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f1823c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in ../data-capture/TherapySessionRecordings/audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# conver the video to an audio file\n",
    "\n",
    "video_path = '../data-capture/TherapySessionRecordings/20230613_161520.mp4'\n",
    "video = VideoFileClip(video_path)\n",
    "audio = video.audio\n",
    "audio_file_path = \"../data-capture/TherapySessionRecordings/audio.wav\"\n",
    "audio.write_audiofile(audio_file_path)\n",
    "video.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b181951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import math\n",
    "\n",
    "\n",
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.loads(f.read())\n",
    "\n",
    "url = \"https://usecase1hub1533117385.cognitiveservices.azure.com/speechtotext/transcriptions:transcribe?api-version=2024-11-15\"\n",
    "\n",
    "headers = {\n",
    "    \"Ocp-Apim-Subscription-Key\": config[\"SUBSCRIPTION_KEY\"],\n",
    "    \"Accept\": \"application/json\"\n",
    "}\n",
    "\n",
    "files = {\n",
    "    \"audio\": open(audio_file_path, \"rb\"),\n",
    "    \"definition\": (None, '{\"locales\":[\"en-US\"], \"diarization\": {\"maxSpeakers\": 4,\"enabled\": true}}', 'application/json')\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, files=files)\n",
    "\n",
    "#transcribe the video with diarization enabled\n",
    "r_json = response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f36d2e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_milliseconds_to_minute_timestamps(ms):\n",
    "    seconds = ms/1000\n",
    "    minutes = int(seconds//60)\n",
    "    rem_seconds = int(math.floor(seconds - minutes * 60))\n",
    "    return f'{minutes}:{rem_seconds:02}'\n",
    "    \n",
    "# add formatted timestamps for the video\n",
    "for phrase in r_json[\"phrases\"]:\n",
    "    phrase[\"Timestamp\"] = convert_milliseconds_to_minute_timestamps(phrase['offsetMilliseconds'])\n",
    "    for word in phrase[\"words\"]:\n",
    "        word[\"Timestamp\"] = convert_milliseconds_to_minute_timestamps(word['offsetMilliseconds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5806fc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker 2 pauses or repeats themselves in the following instances:\n",
      "\n",
      "- **Pause:** \n",
      "  - **Timestamp:** \"0:10\" to \"0:12\"\n",
      "  - **Duration:** 2 seconds\n",
      "  - **Transcript:** Between \"the\" and \"unsalted\" in the phrase \"I'm shopping for the unsalted butter for Father's Day.\"\n",
      "\n",
      "- **Repetition:**\n",
      "  - **Timestamp:** \"0:25\"\n",
      "  - **Transcript:** \"Talk to you soon.\" This phrase is repeated by Speaker 2 and then by Speaker 1.\n"
     ]
    }
   ],
   "source": [
    "# pass the transcribed text to chatgpt for analysis and chat\n",
    "\n",
    "system = \"\"\"\n",
    "You will be given a json object that is an audio transcription of a therapy session with a patient with autism.\n",
    "Your job is to answer questions about the data, e.g. at what time stamps did speaker 1 start and end conversations, \n",
    "or where did speaker 1 hesitate?\n",
    "\n",
    "Return your output as a markdown, with bulleted lists where appropriate.\n",
    "\n",
    "If you provide any relevant time stamps, always include the transcript for words or phrases that were spoken at those \n",
    "time stamps. Only refer to the \"Timestamp\" attribute for phrases when providing timestamps. If you provide a duration gap,\n",
    "convert the gap to seconds instead of milliseconds.\n",
    "\"\"\"\n",
    "\n",
    "endpoint = \"https://usecase1hub1533117385.openai.azure.com/\"\n",
    "model_name = \"gpt-4\"\n",
    "deployment = \"gpt-4\"\n",
    "\n",
    "subscription_key = config[\"SUBSCRIPTION_KEY\"]\n",
    "api_version = \"2024-12-01-preview\"\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=subscription_key,\n",
    ")\n",
    "\n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": system},\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": json.dumps(r_json[\"phrases\"])\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "def interface_with_gpt(messages, user_query, append_response=False):\n",
    "    messages.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_query\n",
    "    })\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        max_tokens=4096,\n",
    "        temperature=.9,\n",
    "        top_p=.5,\n",
    "        model=deployment\n",
    "    )\n",
    "    \n",
    "    if append_response:\n",
    "        messages.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": response.choices[0].message.content\n",
    "        })\n",
    "    \n",
    "    return response, messages\n",
    "\n",
    "\n",
    "\n",
    "user_query = \"Where does the patient (speaker 2) start and end conversations?\"\n",
    "user_query_2 = \"Where does the patient (speaker 2) pause or repeat themselves?\"\n",
    "\n",
    "response, messages = interface_with_gpt(messages, user_query_2, append_response=True)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1f43d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "response, _ = interface_with_gpt(messages, \n",
    "                   \"I was only looking for portions of the transcript where the Speaker 1 repeated themselves, not where speaker 1 echoed speaker 2. Refine your output accordingly\", \n",
    "                   append_response=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "159ddb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker 2 (the patient) does not repeat themselves in the provided transcript. There are no instances where Speaker 2 repeats a word or phrase by themselves. The repetition noted earlier was an echo by Speaker 1, not a self-repetition by Speaker 2.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b69556",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
